---
title: "Amazon Reviews Sentiment Analysis"
author: "Mirza Naseh Ahmad"
date: "3/8/2021"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


#initialization

if(!"pacman" %in% installed.packages()[,"Package"]) install.packages("pacman")
pacman::p_load(BiocManager, plyr, dplyr, readr, ggplot2 ,stringr, syuzhet, RColorBrewer,wordcloud, NLP, tm, SnowballC, knitr, tidytext, tidyr,RSentiment, DT, sqldf, tidyverse, text2vec, fastTextR, tokenizers, caTools, class, rvest, caret, quanteda, doSNOW, e1071, obliqueRF, lattice,skimr)

options(stringsASFacgtors = FALSE)
library(quanteda)
library(dplyr,tidyverse)
library(tidyverse)
library(text2vec)
library(SnowballC)
library(tidytext)
library(stringr)
library(stopwords)
library(tokenizers)
require(dplyr)
require(data.table)
require(caTools)
library(fastTextR)
library(ggplot2)
library(doSNOW)
library(e1071)
library(obliqueRF)
library(caret,lattice)
library(skimr)
```

```{r Automotive Reviews}
#setting the working directory
setwd('E:\\Ryerson\\CIND820\\Code')
#Loading the Data

#downloading the data from the source
#fn <- "amazon_reviews_us_Automotive_v1_00.tsv.gz"

#if ( !file.exists(fn) ) {
# download.file("https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Automotive_v1_00.tsv.gz",
#               fn)
#  untar(fn)
#}
```

```{r Data and EDA}

datacomplete<-as.data.frame(fread('amazon_reviews_us_Automotive_v1_00.tsv'),stringsAsFactors = FALSE, quote ="")
sampledata<-summary(datacomplete)

skimmed <- skim_to_wide(datacomplete)
skimmed[, c(1:5, 9:11, 13, 15:16)]


vine<-as.factor(datacomplete$vine)
summary(vine)

#Marketplace where the review was written.
marketplace<- as.factor(datacomplete$marketplace)
summary(marketplace)

#total Unique Customers
uniquecustomers <- unique(datacomplete$customer_id)
length(uniquecustomers)

#total Unique products reviewed
uniqueproducts <- unique(datacomplete$product_id)
length(uniqueproducts)

#Textlength 
datacomplete$reviewlength <- nchar(datacomplete$review_body)

summary(datacomplete$reviewlength)

#Highest rated products.
top_rated_products <- datacomplete %>%
  group_by(product_id) %>% 
  summarize(count_votes = n()) %>% 
  arrange(desc(count_votes))

top_rated_products1 <- top_rated_products[top_rated_products$count_votes > 10 ,]

head(top_rated_products1)

data<- datacomplete[datacomplete$product_id %in% top_rated_products1$product_id ,]

str(data)

#Star Rating
srating<-datacomplete$star_rating
hist(srating)
prop.table(table(srating))



#Data Prep
datacomplete$reviewlength <- nchar(datacomplete$review_body)

summary(datacomplete$reviewlength)
str(datacomplete)

#removing "NA" values

datacomplete<-na.omit(datacomplete)

skimmed <- skim_to_wide(datacomplete)
skimmed[, c(1:5, 9:11, 13, 15:16)]

#removing zero text values
zerotext<-datacomplete[datacomplete$reviewlength == 0 ,]


datacomplete<-datacomplete[datacomplete$reviewlength != 0,]



#filtering out non verified purchases
vpcount = table(datacomplete$verified_purchase)
vpcount = as.data.frame(vpcount)
names(vpcount)[1] = 'Verified purchase'
vpcount


datavp<-datacomplete[datacomplete$verified_purchase != 'N' & datacomplete$product_id %in% top_rated_products1$product_id,]
datavp$star_rating <- as.factor(datavp$star_rating)
datavp$star_rating <- ordered(datavp$star_rating, levels = c("5", "4", "3", "2", "1"))

table(datavp$verified_purchase)
summary(datavp$reviewlength)
glimpse(datavp)

#Stratified Sampling
set.seed(1000)
options(stringsASFacgtors = FALSE)
sr1<- filter(datavp, star_rating == 1)
sr2<- filter(datavp, star_rating == 2)
sr3<- filter(datavp, star_rating == 3)
sr4<- filter(datavp, star_rating == 4)
sr5<- filter(datavp, star_rating == 5)

sampledata1<- sample_n(sr1,1000 , replace = FALSE)
sampledata2<- sample_n(sr2,1000 , replace = FALSE)
sampledata3<- sample_n(sr3,1000 , replace = FALSE)
sampledata4<- sample_n(sr4,1000 , replace = FALSE)
sampledata5<- sample_n(sr5,1000 , replace = FALSE)

sampledata <- rbind(sampledata1, sampledata2, sampledata3, sampledata4, sampledata5)
sampledata <- data.table(rating = sampledata$star_rating ,review = sampledata$review_body , reviewlength = sampledata$reviewlength)

data <- data.table(rating = datavp$star_rating ,review = datavp$review_body , reviewlength = datavp$reviewlength)

set.seed(10)
datareduction <- sample(1:nrow(datacomplete), 0.014225 * nrow(datacomplete))
data<- data[datareduction, ]


glimpse(data)
glimpse(sampledata)


round(100*prop.table(table(data$rating)), digits = 2)
SRFactor <- as.factor(data$rating)
barplot(round(100*prop.table(table(data$rating)), digits = 2), xlab = "Star Rating", ylab = "% Frequency", main = "% Data By Star Rating Original Data", col = c(brewer.pal(9,"YlGnBu")))

round(100*prop.table(table(sampledata$rating)), digits = 2)
SRFactor <- as.factor(sampledata$rating)
barplot(round(100*prop.table(table(sampledata$rating)), digits = 2), xlab = "Star Rating", ylab = "% Frequency", main = "% Data By Star Rating Stratified Data", col = c(brewer.pal(9,"YlGnBu")))

glimpse(data)
glimpse(sampledata)




#Splitting the data into training and test set (70/30 split)

set.seed(1002)
indexes<- createDataPartition(data$rating, times = 1 ,p = 0.7, list = FALSE)
train<-data[indexes,]
test <- data[-indexes,]
train <- data.table(rating = train$rating ,review = train$review , reviewlength = train$reviewlength)
test <- data.table(rating = test$rating ,review = test$review , reviewlength = test$reviewlength)

glimpse(train)
glimpse(test)

set.seed(1001)
indexes1<- createDataPartition(sampledata$rating, times = 1 ,p = 0.7, list = FALSE)
train1 <- sampledata[indexes1,]
test1 <- sampledata[-indexes1,]

glimpse(train1)
glimpse(test1)

#Splitting Data into Positive, Negative and neutral reviews, by star rating

sampledatay3 <-train[train$rating == 3, ]
sampledatay5 <-train[train$rating > 3 ,]
sampledatay1 <-train[train$rating <3 ,]
glimpse(sampledatay3)

#stratified sample
sampledatay31 <-train1[train1$rating == 3 ,]
sampledatay51<-train1[train1$rating > 3 ,]
sampledatay11 <-train1[train1$rating <3 ,]
glimpse(sampledatay31)


#cleaning up the text and removing special characters

fix.contractions <- function(doc) {
  doc <- gsub("won't", "will not", doc)
  doc <- gsub("can't", "can not", doc)
  doc <- gsub("n't", " not", doc)
  doc <- gsub("'ll", " will", doc)
  doc <- gsub("'re", " are", doc)
  doc <- gsub("'ve", " have", doc)
  doc <- gsub("'m", " am", doc)
  doc <- gsub("'d", " would", doc)
  doc <- gsub("<br />", "", doc)
  doc <- gsub("\n", "", doc)
  # 's could be 'is' or could be possessive: it has no expansion
  doc <- gsub("'s", "", doc)
  doc<- gsub("miss.","",doc)
  doc<- gsub("mr.","",doc)
  return(doc)
}
removeSpecialChars <- function(x) gsub("[^a-zA-Z0-9 ]", " ", x)

reduced_data <- data.table(sampledatay3)
reduced_data5 <- data.table(sampledatay5)
reduced_data1 <- data.table(sampledatay1)


reduced_data$review <- tolower(reduced_data$review)
reduced_data$review <- sapply(sampledatay3$review, removeSpecialChars)
reduced_data$review <- sapply(reduced_data$review, fix.contractions)

reduced_data5$review <- tolower(reduced_data5$review)
reduced_data5$review <- sapply(sampledatay5$review, removeSpecialChars)
reduced_data5$review <- sapply(reduced_data5$review, fix.contractions)



reduced_data1$review <- sapply(sampledatay1$review, removeSpecialChars)
reduced_data1$review <- sapply(reduced_data1$review, fix.contractions)
reduced_data1$review <- tolower(reduced_data1$review)

reviewtext<-reduced_data$review
reviewtext5<-reduced_data5$review
reviewtext1<-reduced_data1$review

glimpse(reviewtext)

revtext <- data.table(words = c(reviewtext))
revtext5 <- data.table(words = c(reviewtext5))
revtext1 <- data.table(words = c(reviewtext1))

glimpse(revtext)
summary(revtext)
```


```{r Sentiment Analysis}

set.seed(100)
alltext<-c(revtext,revtext5, revtext1)
corpus <- VCorpus(VectorSource((alltext)))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeWords, stopwords('english'))
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, PlainTextDocument)
tdm <- TermDocumentMatrix(corpus)
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)

wordcloud(d$word,d$freq,c(3,.51),2,100,FALSE,.1,colors = brewer.pal(8,"Dark2"))

#AFINN Lexicon 

rta <- data.table(review = c(revtext$words))
review_sentiment <- rta %>%
    unnest_tokens(word, review, token = "words") %>%
    inner_join(get_sentiments("afinn"))  %>%
    filter(!nchar(word) < 3) %>% 
    anti_join(stop_words)


glimpse(review_sentiment)
    
rta5 <- data.table(review = c(revtext5$words))
review_sentiment5 <- rta5 %>%
    unnest_tokens(word, review, token = "words") %>%
    inner_join(get_sentiments("afinn"))  %>%
    filter(!nchar(word) < 3) %>% 
    anti_join(stop_words)
    
rta1 <- data.table(review = c(revtext1$words))
review_sentiment1 <- rta1 %>%
    unnest_tokens(word, review, token = "words") %>%
    inner_join(get_sentiments("afinn"))  %>%
    filter(!nchar(word) < 3) %>% 
    anti_join(stop_words)

count<-table(review_sentiment5$value + review_sentiment$value + review_sentiment1$value)

nchar(review_sentiment1)
nchar(review_sentiment5)
nchar(review_sentiment)

barplot(count, main="Reviews", xlab="polarity of sentiments",ylab = "frequency", col = brewer.pal(11,"RdYlBu")) 


count<-table(review_sentiment5$value)

barplot(count, main="5 Star Reviews",
        xlab="polarity of sentiments",ylab = "frequency", col = brewer.pal(10,"RdYlBu")) 

count<-table(review_sentiment$value)

barplot(count, main="3 Star Reviews",
        xlab="polarity of sentiments", col = brewer.pal(10,"RdYlBu")) 

count<-table(review_sentiment1$value)

barplot(count, main="1 Star Reviews",
        xlab="polarity of sentiments", col = brewer.pal(10,"RdYlBu")) 


p_sent<-review_sentiment[review_sentiment$value>= 0,]
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
set.seed(100)
wordcloud(p_sent$word,max.words = 100,colors=brewer.pal(6,"Dark2"),scale=c(4,.5))

?wordcloud


n_sent<-review_sentiment[review_sentiment$value< 0,]
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
set.seed(100)
wordcloud(n_sent$word,max.words = 100,colors=brewer.pal(6,"Dark2"),scale=c(4,.5))


p_sent5<-review_sentiment5[review_sentiment5$value>= 0,]

layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
set.seed(100)
wordcloud(p_sent5$word,max.words = 100,colors=brewer.pal(8,"Dark2"),scale=c(4,.5))

p_sent1<-review_sentiment1[review_sentiment1$value>= 0,]
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
set.seed(100)
wordcloud(p_sent1$word,max.words = 100,colors=brewer.pal(8,"Dark2"),scale=c(4,.5))



n_sent5<-review_sentiment5[review_sentiment5$value< 0,]
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
set.seed(100)
wordcloud(n_sent5$word,min.freq=25,colors=brewer.pal(8,"Dark2"),scale=c(4,.5))


n_sent1<-review_sentiment1[review_sentiment1$value< 0,]
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
set.seed(100)
wordcloud(n_sent1$word,min.freq=100,colors=brewer.pal(6,"Paired"),scale=c(4,.5))

#BING Lexicon

rtb <- data.table(review = c(revtext$words))
review_sentimentb <- rta %>%
    unnest_tokens(word, review, token = "words") %>%
    inner_join(get_sentiments("bing"))
str(review_sentimentb)

countb<-table(review_sentimentb$sentiment)

barplot(countb, main="Sentiment distribution",
        ylab="Number of sentiments", col = c("red","blue"))


pos_sent<-review_sentimentb[review_sentimentb$sentiment == 'positive',]
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
set.seed(100)

wordcloud(pos_sent$word,max.words = 100,colors=brewer.pal(8,"Dark2"),scale=c(4,.5))


neg_sent<-review_sentimentb[review_sentimentb$sentiment == 'negative',]
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
set.seed(100)


wordcloud(neg_sent$word,max.words = 100,colors=brewer.pal(6,"Paired"),scale=c(4,.5))

#Syuzhet’s package


algotext<-gsub("http[^[:blank:]]+","",alltext)
algotext<-gsub("@\\w+","",algotext)
algotext<-gsub("[[:punct:]]"," ",algotext)
algotext<-gsub("[^[:alnum:]]"," ",algotext)
algotext<-gsub("Miss."," ",algotext)
algotext<-gsub("Mr."," ",algotext)

algosent<-get_nrc_sentiment((algotext))


algosent.positive =sum(algosent$positive)
algosent.anger =sum(algosent$anger)
algosent.anticipation =sum(algosent$anticipation)
algosent.disgust =sum(algosent$disgust)
algosent.fear =sum(algosent$fear)
algosent.joy =sum(algosent$joy)
algosent.sadness =sum(algosent$sadness)
algosent.surprise =sum(algosent$surprise)
algosent.trust =sum(algosent$trust)
algosent.negative =sum(algosent$negative)

colSums(algosent)
head(algosent)
yAxis <- c(algosent.positive,
           + algosent.anger,
           + algosent.anticipation,
           + algosent.disgust,
           + algosent.fear,
           + algosent.joy,
           + algosent.sadness,
           + algosent.surprise,
           + algosent.trust,
           + algosent.negative)
xAxis <- c("Negative","Anger","Anticipation","Disgust","Fear","Joy","Sadness","Surprise","Trust","Positive")
yRange <- range(0,yAxis) + 500
barplot(yAxis, names.arg = xAxis,
        xlab = "Emotional valence", ylab = "Score", main = "Emotional Valence", col = brewer.pal(10,"RdYlBu"))
```